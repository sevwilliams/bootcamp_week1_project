{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis , Regression, Data Wrangling and Visualization Challenges\n",
    "\n",
    "We are going to explore some of this movie data. It comes from two\n",
    "separate sources, boxofficemojo.com and metacritic.com. The data is\n",
    "stored in files under directories related to these sources. The data\n",
    "for each movie is stored in its own file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 1\n",
    "\n",
    "**First of all, before you do any of these challenges, start a *eda-and-reg* branch in your repository if you haven't done so already.** You will commit the additions you make while solving these challenges to that branch. In the end, you will submit your work by making a pull request.\n",
    "\n",
    "\n",
    "Start a new ipython notebook in the `project_1` directory. We will read the\n",
    "data from the boxofficemojo files. The files are in json format, which\n",
    "is a way to serialize key-value pairs. It looks exactly like how\n",
    "python shows the contents of a dictionary. For example,\n",
    "\n",
    "    {\"Ryan Gosling\": 9,\n",
    "    \"George Clooney\": 8,\n",
    "    \"Irmak Sirer\": 11}\n",
    "\n",
    "is a valid json format. (It can be more complex than that, for example\n",
    "the values might be nested lists, or more dictionaries, etc.)\n",
    "Import the `os` module to be able to modify/access filesystem\n",
    "commands, and the `json` module so we can parse these.\n",
    "\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "the relative path to the data directory (since you are already in the\n",
    "`project_1` directory) is defined as `data/boxofficemojo/` in a Mac (or\n",
    "linux) system, and as `data\\boxofficemojo\\` in a Windows\n",
    "system. However, you don't need to know on what kind of system this\n",
    "will be run if you use the `os` module:\n",
    "\n",
    "    DATA_DIR = os.path.join('data', 'boxofficemojo')\n",
    "\n",
    "will put the correct path in `DATA_DIR`. `os.path.join` basically\n",
    "combines elements of a path in the correct way for the system.\n",
    "\n",
    "Let's say we know the filename to a specific file:\n",
    "`mojo_bladerunner.json`. You can get the path to it with\n",
    "\n",
    "    target_file_name = 'mojo_bladerunner.json'\n",
    "    target_file_path = os.path.join(DATA_DIR, target_file_name)\n",
    "\n",
    "Once a file is opened for reading, the `load` function from the `json`\n",
    "module will convert this string into a python dictionary:\n",
    "\n",
    "    with open(target_file_path, 'r') as target_file:\n",
    "        movie = json.load(target_file)\n",
    "\n",
    "Now `movie` is a dictionary. You can look at its contents with `print\n",
    "movie`, but a more readable pretty-print format is provided by the\n",
    "`pprint` module:\n",
    "\n",
    "    from pprint import pprint\n",
    "    pprint(movie)\n",
    "\n",
    "will show you the contents in a neatly organized way. You can learn\n",
    "more about each field in the README file within the data folder.\n",
    "\n",
    "You initial challenge is to make a single list of movies. Every\n",
    "single movie in that boxofficemojo directory should be a dictionary in this list. There is a single json file for each movie. Read all this information into a python dictionary, and put the dictionary into the list. When you do this for every movie, you will end up with one big list.\n",
    "Call this list `movies`. How many movies are there?\n",
    "\n",
    "Final hint: The `listdir` function from `os`  gives you a list of all\n",
    "filenames in a given directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 2\n",
    "\n",
    "What years are the movies from? Are they mostly recent? How far back\n",
    "do they go? In a new cell, make a list of years in the\n",
    "dataset. Extract the year field and put the year value for each movie\n",
    "into a single list. Let's call this list `movie_years`. Now we want to\n",
    "count the years. What we want is something like a dictionary, with\n",
    "each year as a key, and the corresponding value is the number of\n",
    "movies from that year in the dataset.\n",
    "\n",
    "Hint: Check out the `Counter` class from the `collections` module. You\n",
    "don't have to use it but it makes things pretty easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 3\n",
    "\n",
    "Start a new cell. Pretty-printing the result of the previous challenge gives you a\n",
    "decent idea, but let's make a real histogram. Let's make sure ipython\n",
    "notebook shows the graphs inline and we import the necessary plotting\n",
    "stuff:\n",
    "\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "\timport seaborn as sns\n",
    "\n",
    "The documentation for plotting a histogram with matplotlib is\n",
    "[here](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist),\n",
    "but it is basically as easy as doing\n",
    "\n",
    "    plt.hist(movie_years)\n",
    "\n",
    "but if you try this now you should get an error. What happened? It\n",
    "says `NoneType` in the error. If you look in carefully you might see\n",
    "that some of the years were `None` in `movie_years`. That's because\n",
    "year data was missing for a handful of movies on boxofficemojo, and\n",
    "the value is `None`. (How many of them are there?) Clean those out\n",
    "from your list of years and plot a histogram. Give it a title by\n",
    "adding a line\n",
    "\n",
    "    plt.title('Your title goes here\")\n",
    "\n",
    "Note: We imported seaborn but do not seem to use it. However, just the\n",
    "act of importing seaborn changes the harsh default color scheme and\n",
    "other visual settings of `matplotlib` and makes the plots made with it\n",
    "look better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 4\n",
    "\n",
    "Let's look at something else. Make a histogram of the domestic gross\n",
    "numbers. With a regular histogram, however, you can't really see much,\n",
    "since low gross movies dominate the dataset. Use a log scale\n",
    "(logarithm of gross is much easier to read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 5\n",
    "\n",
    "Make a histogram of title lengths (number of characters in the movie's\n",
    "title). Add labels to the x and y axes to make it clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 6\n",
    "\n",
    "Ok, now let's do this with pandas.\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "Assuming you called your original list of dictionaries with all the films\n",
    "`movies`, you can do this:\n",
    "\n",
    "    movies_df = pd.DataFrame(movies)\n",
    "    movies_df['year'].hist()\n",
    "\n",
    "This gives us a histogram of movies.\n",
    "\n",
    "You can see that we don't have a lot before the 80's. Let's focus on\n",
    "the last 25 years. You can filter with a boolean expression like this:\n",
    "\n",
    "    recent_movies = movies_df[movies_df['year']>=1990]\n",
    "\n",
    "Now `recent_movies` is a dataframe only with movies released\n",
    "after 1990. Make a histogram of these only, make sure they are all\n",
    "indeed after 1990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 7\n",
    "\n",
    "Like a histogram, pandas makes it easy to do other types of plots as\n",
    "well. Make a boxplot of domestic grosses, grouped by year. So, for\n",
    "each year you should have a boxplot showing the distribution. Do this\n",
    "for only movies released at or after 1990.\n",
    "\n",
    "Hint: You can do this with a single, simple line of code.\n",
    "\n",
    "Once you have it, try to play with its size, limits of y-axis, etc. to\n",
    "make it big and readable. You wouldn't want things to overlap each\n",
    "other, or be tiny and squeezed together in a way that would hinder you\n",
    "from understanding what's going on with grosses over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 8\n",
    "\n",
    "Let's take a look at the dataframe. if you do\n",
    "\n",
    "    movies_df.head()\n",
    "\n",
    "it will show the first five rows, and ipython notebook will show it in\n",
    "a nice format. One thing you could notice is that the production\n",
    "budget values are missing from 2 movies even among these 5. That NaN\n",
    "(not-a-number) is how pandas treats missing values. They are like\n",
    "NULLs in a SQL database. Pandas is smart enough to not count them as\n",
    "real values, keeps them out of the calculation if you need the mean,\n",
    "etc. If you do\n",
    "\n",
    "    movies_df.describe()\n",
    "\n",
    "you get a nice report on every column in the data, allowing you to\n",
    "inspect and get a feel for each of them. You can see the\n",
    "count is much lower on production budget, this means a lot of NaNs.\n",
    "\n",
    "Make a new dataframe that only has movies for which we have budget\n",
    "information. How many are left?\n",
    "\n",
    "Hint: You want to look for the `dropna` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 9\n",
    "\n",
    "Make a scatterplot of the opening weekend take versus domestic gross\n",
    "for all the movies. Also report on how many movies have both of these\n",
    "values (how many are you losing since one of these is missing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching to Regression Before Challenge 10\n",
    "\n",
    "Ok. Let's do a linear regression. There are two main packages for that\n",
    "in python. `statsmodels` imitates R in terms of its interface, and\n",
    "gives a lot of information/diagnostics in a neat table. It is mostly\n",
    "good for linear and logistic regression, and generalized linear models\n",
    "in general. `scikit.learn` is python's big machine learning\n",
    "library. It has a lot of machine learning algorithms (including linear\n",
    "regression), uses the same interface for all of them (makes it very\n",
    "easy), and is very actively developed, with more features added very\n",
    "frequently. It's main disadvantage is that it does not provide a\n",
    "summary table like `statsmodels`.\n",
    "\n",
    "Let's start with statsmodels. Make a dataframe called df that has both\n",
    "the opening weekend take and the domestic gross columns, and drop all\n",
    "rows with missing data. Call this new dataframe `df`. Now let's fit a model.\n",
    "\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    Y = df.domestic_gross\n",
    "    X = sm.add_constant(df.opening_weekend_take)\n",
    "\n",
    "    linmodel = sm.OLS(Y,X).fit()\n",
    "\n",
    "We are taking the domestic_gross column as our Y variable. X will be a matrix\n",
    "including all feature columns. But why did we not do  `X =\n",
    "df.opening_weekend_take`? Well, `statsmodels` does not like to treat\n",
    "the intercept as a special part of the model. As a design choice, it\n",
    "wants to treat is just like any other feature that you multiply with a\n",
    "parameter, however the value for this feature is always one. So, to\n",
    "have an intercept, you would have to andd a column that has the value\n",
    "1 for every row. To make it easy to do so, they added this\n",
    "`add_constant` function, which does exactly that. So now our X is a\n",
    "matrix with two columns: opening weekend take, and a constant column\n",
    "that's all 1s.\n",
    "\n",
    "The fitting is done in one line. Note that Y comes before X. This is\n",
    "the `statsmodels` design choice (`scikit.learn` does it the other\n",
    "way).\n",
    "We now have a linear model trained on\n",
    "the X and Y data.\n",
    "\n",
    "Switch to a new cell and execute\n",
    " \n",
    "    linmodel.summary()\n",
    "\n",
    "This is the table that statsmodels presents with a lot of information\n",
    "about the model. You are likely to recognize some or most of\n",
    "these reported metrics. Later in class, we will go over each of them\n",
    "to make sure there are no gaps left.\n",
    "\n",
    "And finally, switch to a new cell:\n",
    "\n",
    "    predicted_gross = linmodel.predict(X)\n",
    "    plt.scatter(df.opening_weekend_take, df.domestic_gross, color='gray')\n",
    "    plt.plot(df.opening_weekend_take, predicted_gross)\n",
    "    plt.title(\"Opening Weekend Based Model for Domestic Gross\")\n",
    "    plt.xlabel(\"Opening Weekend Take ($100M)\")\n",
    "    plt.ylabel(\"Domestic Gross ($100M)\")\n",
    "\n",
    "Here we are first getting the predictions for each movie that we used\n",
    "in fitting. We are basically asking, what is the expected value that\n",
    "the model thinks is for this opening_weekend_take?\n",
    "We then make a scatterplot of all movies in a gray color to pepper the\n",
    "background showing where observed values fall.\n",
    "Next, we plot the predictions (which form a line since this is a\n",
    "single feature model).\n",
    "Finally we add a title and labels.\n",
    "\n",
    "You are now ready to continue with the challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 10\n",
    "\n",
    "Make a scatterplot of actual domestic gross versus predicted domestic\n",
    "gross. Also plot a line that shows what ideal predictions would\n",
    "be. Anything above that line is over-prediction, anything below is\n",
    "underprediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 11\n",
    "\n",
    "Make a scatterplot of predicted gross versus residuals. Also plot a\n",
    "line that takes the residual value 0 for every gross. We are assuming\n",
    "that the random part of our model is a normal distribution with the\n",
    "mean zero. So, ideally, the residuals should be forming a band around\n",
    "this zero line, and the range shouldn't change. This plot helps you\n",
    "check that assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 12\n",
    "\n",
    "We're talking about money (opening weekend and total gross), and\n",
    "usually, in many real life problems, orders of magnitude of features that spread over such\n",
    "large scales may be better suited to such models than the values\n",
    "themselves.\n",
    "\n",
    "Instead of predicting gross with opening weekend, build a model that\n",
    "predicts log(gross) with log(opening weekend).\n",
    "\n",
    "- Print the summary\n",
    "- Plot log(opening) vs log(gross) (and the fitted line)\n",
    "- Plot the residuals over log(gross)\n",
    "\n",
    "(Does it look better or worse? What are the problems?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 13\n",
    "\n",
    "Make a predictive model for log(domestic gross) with two features:\n",
    "log(opening weekend) and square of log(opening weekend). We are\n",
    "building a quadratic model. Make the residual plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 14\n",
    "\n",
    "`statsmodels` also allows you to build models using formulas. That can\n",
    "come in handy if the features and their functional forms start getting\n",
    "a bit complicated. Build the same quadratic model from the previous\n",
    "challenge, but do it with a formula. Use\n",
    "\n",
    "    import statsmodels.formula.api as smf\n",
    "\n",
    "Then define a formula that looks something like this:\n",
    "\n",
    "    formula = 'target_column_name ~  feature_1 + feature_2'\n",
    "\n",
    "where the `target_column_name`, `feature_1` and `feature_2` will be\n",
    "replaced with column names in your dataframe, and then use the\n",
    "`ols` function from the imported module which we called `smf` to use\n",
    "the formula on your data. Make sure the model is exactly the same as\n",
    "the one from the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 15\n",
    "\n",
    "Let's see how doing linear regression works in `scikit.learn`:\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    Y = df['domestic_gross']\n",
    "    X = df[['opening_weekend_take']]\n",
    "    model.fit(X, Y)\n",
    "\n",
    "Pretty straightforward. One thing of note is the double bracket for\n",
    "X. For Y, `sklearn` expects a single column, one array. However, for X,\n",
    "it expects a matrix, with one column each for every feature we include\n",
    "in our model. Here, we are only including one, but it still expects\n",
    "not a single vector, but a matrix with only one column. When we put a\n",
    "list of column names within the brackets for a pandas dataframe, it\n",
    "gives us a new dataframe with all the columns. In the same spirit, we\n",
    "are here giving it a list, so we can get a Dataframe (a matrix) and\n",
    "not a Series (a vector) so as not to confuse `sklearn`. Also, note that\n",
    "the `fit` method is called with X first, then Y. And we don't need to\n",
    "do anything extra about the intercept.\n",
    "\n",
    "Ok, `sklearn` does not provide a summary table. If you need to look at\n",
    "the coefficients and the intercept:\n",
    "\n",
    "    print model.coef_\n",
    "    print model.intercept_\n",
    "\n",
    "If you need to calculate the mean squared error of the model:\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    Y_pred = model.predict(X)\n",
    "    Y_true = Y\n",
    "    print mean_squared_error(Y_pred, Y_true\n",
    "\n",
    "and so on... Scikit.learn has a lot of tools to inform you about the\n",
    "model but you have to import and use them separately, one by one.\n",
    "\n",
    "Now, to the challenge. Fit the quadratic log model again, but this\n",
    "time with `scikit.learn`. Compare the results with what you got from `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching from iPython Notebook to Standalone Scripts\n",
    "\n",
    "Save and close your notebook. For the rest of the challenges, we will\n",
    "use standalone scripts. You can edit them with Atom, and run the file\n",
    "by running `python scriptname.py` on a terminal (replacing\n",
    "*scriptname* with your filename, of course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 16\n",
    "\n",
    "We will write code to load data from boxofficemojo files again, in a function within a module. This is\n",
    "pretty much the same process as in Challenge 1, but this time not in\n",
    "an interactive environment, but in an Atom editor. We will have\n",
    "reusable code in the end, which is a big win.\n",
    "\n",
    "* For things like loading, cleaning, and merging data, it’s often best to do these things in a Python module instead of a Jupiter notebook, so that you can reuse the code easily in other modules later. Make a new Python module (aka .py file) called `loaddata.py` in the Project 1 directory.\n",
    "* Write a [“docstring”](https://en.wikipedia.org/wiki/Docstring#Python) at the top of the module describing what it’s for.\n",
    "* Under your docstring, add the following code, which gets the full filepath for accessing the directory our data lives in:\n",
    "\n",
    "```python\n",
    "# imports\n",
    "import os\n",
    "\n",
    "# constants\n",
    "CURRENT_DIR = os.path.dirname(os.path.realpath(__file__))\n",
    "DATA_DIR = os.path.abspath(os.path.join(CURRENT_DIR, 'data'))\n",
    "MOJO_DIR = os.path.join(DATA_DIR, 'boxofficemojo')\n",
    "```\n",
    "\n",
    "> os.path.join is used for joining filepaths together. To find out why you should use os.path.join instead of just joining strings together, find a classmate with the opposite OS of you and ask them to print `MOJO_DIR` on their machine.\n",
    "\n",
    "* Make a main function and use `os.listdir` to see the contents of the `MOJO_DIR` directory. Use `os.path.join` to build a path to one file in that directory, and open it using `open()`.\n",
    "* Print the contents of the file you opened. Looks kinda like a Python dictionary, right? Double check using Python's `type()` function.\n",
    "* Turns out those files are actually [JSON](https://en.wikipedia.org/wiki/JSON) format. Import Python's built in `json` library at the top of your file and se the `load` or `loads` function to convert the file to a dictionary.\n",
    "  > Bonus: `import pprint from pprint` and call `pprint()` on the resulting dictionary to print it in an easier to read format.\n",
    "\n",
    "* Now that you can load one file, you can load them all. Write a for loop that loops over all the files in the `MOJO_DIR` and appends the dictionaries for each to a list.\n",
    "* Finishing touch: move this work out of your main function and into a real function called `load_mojo_data()`\n",
    "  > In a different python file, or in a Jupyter notebook located in the project 1 directory, you can now do something like this:\n",
    "\n",
    "  ```python\n",
    "  import loaddata\n",
    "  import pandas as pd\n",
    "  movie_dicts = loaddata.load_mojo_data()\n",
    "  movie_df = pd.DataFrame(movie_dicts)\n",
    "  ```\n",
    "\n",
    "  The challenge is to have a working loaddata.py that you can import\n",
    "  and successfully use in this manner for the following challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOOSE YOUR PATH\n",
    "\n",
    "The rest of the challenges are in three groups:\n",
    "\n",
    "- **A.** Modeling with Python\n",
    "- **B.** Data Wrangling with Python\n",
    "- **C.** Data Visualization\n",
    "\n",
    "The order in which you will attack them is up to you. You can start with any of these groups and\n",
    "switch to any other next, based on your interests. These theree groups\n",
    "do not depend on each other and can be tackled separately. Remember to\n",
    "use the python script workflow (as opposed to interactive environment like an\n",
    "ipython notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group A: Modeling with Python\n",
    "\n",
    "#### Challenge 17\n",
    "Draw a histogram of the residuals for one of the regression\n",
    "models. What do their distribution look like? Does it look normally\n",
    "distributed? (Note: To see matplotlib plots when you run them from a\n",
    "python script, you need to add the line `plt.show()` to the end. This\n",
    "opens a new window with the figure in it when you run the python file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 18\n",
    "Build a Domestic Gross model using all the non-categorical features. Include every\n",
    "available numeric feature. How does your model do? Is it safe to include all\n",
    "these features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 19\n",
    "Create a couple of features yourself. Add them as columns in your\n",
    "dataframe. Calculate them from other features. Examples: a) Length of\n",
    "title, b) if it is after 2000 or not (1 if it is, 0 it isn't), number\n",
    "of theaters opened to (opening take/opening per theater), etc. You make\n",
    "others. Put them (among with budget and other features of your choice)\n",
    "in model. See if they look significant. One by one, remove\n",
    "insignificant features and check the residuals. Any change? What is\n",
    "left? (Try different combinations to find a better performing\n",
    "model. Which metric will you use for 'better performance'?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 20\n",
    "Fitting and checking predictions on the exact same data set can be\n",
    "misleading. Divide your data into two sets: a training and a test set\n",
    "(roughly 75% training, 25% test is a fine split). Fit a model on the\n",
    "training set, check the predictions (by plotting versus actual values)\n",
    "in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 21\n",
    "Build a model for predicting gross with multiple features, including\n",
    "budget. Plot a scatterplot with x=budget, y=gross, both for actual\n",
    "values and for predicted values. Predicted values will no longer\n",
    "neatly fall on a line. Why? What's happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group B: Data Wrangling with Python\n",
    "\n",
    "#### Challenge 22\n",
    "\n",
    "Which director in this dataset has the highest average gross per movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 23\n",
    "\n",
    "Add functionality to loaddata.py that loads the data from files in the\n",
    "`data/metacritic` folder similarly to how the code we wrote for\n",
    "boxofficemojo works. Try to reuse as much code as you can, without\n",
    "copy-pasting it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 24\n",
    "\n",
    "BoxofficeMojo data has a couple fields `release_date_limited` and\n",
    "`release_date_wide` that are strings in a \"YYYY-MM-DD\" format. Python\n",
    "has a library called `datetime` for doing useful things with\n",
    "dates. Write a function using the `datetime` library to convert these\n",
    "strings into `datetime.date` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 25\n",
    "\n",
    "Write a function that loads both sources and merges them together,\n",
    "returning as many movies as possible where data is available from both\n",
    "sources. Note that these are scraped data from two different websites,\n",
    "so the fields won't match up in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group C: Data Visualization\n",
    "\n",
    "#### Challenge 26 \n",
    "Fit three different regression models to your data (different feature sets). Plot all of them together on top of the real data. Add a legend so we can see which model is which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 27\n",
    "For a model that predicts either gross or opening weekend with the budget as the single feature, plot all the movies as points, plot the fitted line of the model, plot your model's best predictions for each movie in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 28\n",
    "Continue from previous challenge. Calculate the mean standard error of your model. To each of your prediction points, add an errorbar the size of the mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 29\n",
    "Try drawing the 95% confidence intervals, using `wls_prediction_std` from statsmodels. This page has an example to get you started.\n",
    "\n",
    "> Bonus tip after finishing: Check out [some of seaborne's pre-configured plotting functions](http://stanford.edu/~mwaskom/software/seaborn/tutorial/regression.html) to quickly pull off some nice looking graphs. Also check out the [visual aesthetics tutorial](http://stanford.edu/~mwaskom/software/seaborn/tutorial/aesthetics.html#aesthetics-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
